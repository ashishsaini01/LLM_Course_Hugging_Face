{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e097503b",
   "metadata": {},
   "source": [
    "## Creating a Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1400c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automodel instance\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233a568",
   "metadata": {},
   "source": [
    "The AutoModel class and its associates are actually simple wrappers designed to fetch the appropriate model architecture for a given checkpoint. It’s an “auto” class meaning it will guess the appropriate model architecture for you and instantiate the correct model class. However, if you know the type of model you want to use, you can use the class that defines its architecture directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a9c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88facdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and saving a model\n",
    "model.save_pretrained(\"directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91ad853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json       model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!ls directory_on_my_computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461c0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a model from local directory\n",
    "model = AutoModel.from_pretrained(\"directory_on_my_computer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9062bc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1123ceb882444603b6f1b3960d556903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ee8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pushing a model to the hub\n",
    "model.push_to_hub(\"my-awesome-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13241036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a model from the hub\n",
    "model = AutoModel.from_pretrained(\"your-username/my-awesome-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a05677",
   "metadata": {},
   "source": [
    "## Encoding Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4719b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8075e5f",
   "metadata": {},
   "source": [
    "As a result of tokenizer, we get dict:\n",
    "\n",
    " - input_ids: numerical representations of your tokens\n",
    " - token_type_ids: these tell the model which part of the input is sentence A and which is sentence B (discussed more in the next section)\n",
    " - attention_mask: this indicates which tokens should be attended to and which should not (discussed more in a bit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef1eeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Hello, I ' m a single sentence! [SEP]\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4af8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1731, 1132, 1128, 136, 102, 146, 112, 182, 2503, 117, 6243, 1128, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec99af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  136,  102,  146,  112,  182, 2503,  117, 6243,\n",
      "         1128,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# returning PyTorch tensors\n",
    "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\", return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1370cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  136,  102,    0,    0,    0,    0],\n",
      "        [ 101,  146,  112,  182, 2503,  117, 6243, 1128,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# padding inputs\n",
    "encoded_input = tokenizer(\n",
    "    [\"How are you?\", \"I'm fine, thank you!\"], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c505721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1188, 1110, 170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1263, 5650, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "# Truncating inputs\n",
    "encoded_input = tokenizer(\n",
    "    \"This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long sentence.\",\n",
    "    truncation=True,\n",
    ")\n",
    "print(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  102],\n",
      "        [ 101,  146,  112,  182,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\n",
    "    [\"How are you?\", \"I'm fine, thank you!\"],\n",
    "    padding=True,\n",
    "    truncation=True, # truncating the input\n",
    "    max_length=5,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620526ca",
   "metadata": {},
   "source": [
    "[This Notebook is based on the actual Notebook By Hugging Face](https://huggingface.co/learn/llm-course/chapter2/3?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178a476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tu_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
